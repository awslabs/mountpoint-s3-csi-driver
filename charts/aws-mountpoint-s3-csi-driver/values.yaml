# Default values for ..
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  # Our regional ECR repositories are labelled `eks/aws-s3-csi-driver`.
  # See https://docs.aws.amazon.com/eks/latest/userguide/add-ons-images.html for the per-region registry list.
  # Example: `602401143452.dkr.ecr.us-east-1.amazonaws.com/eks/aws-s3-csi-driver` for us-east-1.
  repository: public.ecr.aws/mountpoint-s3-csi-driver/aws-mountpoint-s3-csi-driver
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "v1.15.0"

node:
  kubeletPath: /var/lib/kubelet
  mountpointInstallPath: /opt/mountpoint-s3-csi/bin/ # should end with "/"
  logLevel: 4
  seLinuxOptions:
    user: system_u
    type: super_t
    role: system_r
    level: s0
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    name: s3-csi-driver-sa
    # Specify the SA's role ARN if running in EKS. Otherwise, the the driver will be "Forbidden" from accessing s3 buckets
    # annotations:
    # "eks.amazonaws.com/role-arn": ""
  nodeSelector: {}
  resources:
    requests:
      cpu: 10m
      memory: 40Mi
    limits:
      memory: 256Mi
  # Tolerates all taints and overrides defaultTolerations
  tolerateAllTaints: false
  defaultTolerations: true
  tolerations: []
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: eks.amazonaws.com/compute-type
                operator: NotIn
                values:
                  - fargate
                  - hybrid
  podInfoOnMountCompat:
    enable: false

sidecars:
  nodeDriverRegistrar:
    image:
      repository: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar
      tag: v2.10.0-eks-1-29-7
      pullPolicy: IfNotPresent
    env:
      - name: KUBE_NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
    volumeMounts:
      - name: plugin-dir
        mountPath: /csi
      - name: registration-dir
        mountPath: /registration
    resources: {}
  livenessProbe:
    image:
      repository: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe
      tag: v2.12.0-eks-1-29-7
      pullPolicy: IfNotPresent
    volumeMounts:
      - mountPath: /csi
        name: plugin-dir
    resources: {}

initContainer:
  installMountpoint:
    resources: {}

controller:
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    name: s3-csi-driver-controller-sa

mountpointPod:
  namespace: mount-s3
  priorityClassName: mount-s3-critical

nameOverride: ""
fullnameOverride: ""

imagePullSecrets: []

awsAccessSecret:
  name: aws-secret
  keyId: key_id
  accessKey: access_key
  sessionToken: session_token

# The default IPv4 address in the credentials URI is in accordance to the references below:
# Doc: https://docs.aws.amazon.com/eks/latest/userguide/pod-id-agent-setup.html
# Source code: https://github.com/aws/eks-pod-identity-agent/blob/8bd71a236522993f02427083e485c83f6ae4fe31/configuration/config.go
eksPodIdentityAgent:
  containerCredentialsFullURI: "http://169.254.170.23/v1/credentials"

# CSI Driver v2 only: If enabled, the driver will continue supporting S3 volumes that were mounted by v1 (SystemD mounts),
# including credential refresh, cleanup, and unmounting these legacy volumes.
# You can set this feature to false for fresh clusters with no v1 volumes,
# or if you've migrated all workloads using S3 volumes after upgrading to v2.
# TODO: Remove this in v3 as systemd mount support will be discontinued
supportLegacySystemDMounts: true

experimental:
  podMounter: false
